# ğŸº Projekt Cerberus Phoenix v2.0 - Cerebro-BFF
# Backend for Frontend z logikÄ… AI i Context Engine

[package]
name = "cerebro-bff"
version = "2.0.0"
edition = "2021"
authors = ["SynergiaOS <202778732+SynergiaOS@users.noreply.github.com>"]
description = "BFF z logikÄ… AI, Context Engine i orkiestracjÄ… agentÃ³w LangChain"
license = "MIT"
repository = "https://github.com/SynergiaOS/Cerebros"
keywords = ["ai", "bff", "context-engine", "qdrant", "llm"]
categories = ["web-programming", "api-bindings", "science"]

[dependencies]
# ğŸš€ Async Runtime & Web Framework
tokio = { version = "1.35", features = ["full"] }
axum = { version = "0.7", features = ["json", "tower-log"] }
tower = { version = "0.4", features = ["full"] }
tower-http = { version = "0.5", features = ["cors", "trace"] }
hyper = { version = "1.0", features = ["full"] }

# ğŸŒ HTTP Client & Serialization
reqwest = { version = "0.11", features = ["json", "rustls-tls"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
uuid = { version = "1.6", features = ["v4", "serde"] }
rand = "0.8"

# ğŸ”´ Redis Caching
redis = { version = "0.24", features = ["tokio-comp"] }

# ğŸŒŠ WebSocket & Streaming
tokio-tungstenite = { version = "0.20", features = ["native-tls"] }
futures-util = "0.3"
async-trait = "0.1"

# ğŸ§  Vector Database (Qdrant)
qdrant-client = { version = "1.7", optional = true }

# ğŸ¤– AI & LLM Integration
async-openai = { version = "0.17", optional = true }
tiktoken-rs = { version = "0.5", optional = true }

# ğŸ“Š Metrics & Monitoring
prometheus = { version = "0.13", optional = true }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"], optional = true }
tracing-opentelemetry = { version = "0.22", optional = true }
opentelemetry = "0.21"

# âš¡ Performance & Utilities
rayon = "1.8"
dashmap = "5.5"
once_cell = "1.19"
anyhow = "1.0"
thiserror = "1.0"
chrono = { version = "0.4", features = ["serde"] }
rust_decimal = { version = "1.33", features = ["serde"] }

# ğŸ”§ Configuration
config = "0.14"
dotenvy = "0.15"

# ğŸ—„ï¸ Database & Storage
sqlx = { version = "0.7", features = ["runtime-tokio-rustls", "postgres", "chrono", "uuid", "macros", "migrate"] }

# ğŸ” Security & Crypto
sha2 = "0.10"
base64 = "0.21"
jsonwebtoken = "9.2"

# ğŸ“ˆ Data Processing
ndarray = "0.15"
candle-core = { version = "0.3", optional = true }
candle-nn = { version = "0.3", optional = true }

# ğŸ§ª Development & Testing
[dev-dependencies]
tokio-test = "0.4"
mockall = "0.12"
criterion = { version = "0.5", features = ["html_reports"] }
proptest = "1.4"

# ğŸ“Š Benchmarks
# [[bench]]
# name = "context_engine_benchmarks"
# harness = false

# [[bench]]
# name = "ai_inference_benchmarks"
# harness = false

# ğŸ¯ Binary Targets
[[bin]]
name = "cerebro-bff"
path = "src/main.rs"

# ğŸ”§ Build Configuration
[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"
strip = true

[profile.dev]
opt-level = 0
debug = true
overflow-checks = true

# ğŸ§ª Test Configuration
[profile.test]
opt-level = 1
debug = true

# ğŸ“¦ Features
[features]
default = ["qdrant", "metrics", "tracing"]
qdrant = ["qdrant-client"]
ai = ["async-openai", "tiktoken-rs", "candle-core", "candle-nn"]
metrics = ["prometheus", "tracing-opentelemetry"]
tracing = ["tracing-subscriber"]

# ğŸ“‹ Metadata
[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]
